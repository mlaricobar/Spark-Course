{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "name": "_merged",
    "colab": {
      "name": "06_K_Nearest_Neighbor.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlaricobar/Spark-Course/blob/master/%5BC-00-ES%5D%20Introduccion%20a%20Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbfhjXF3LVex",
        "colab_type": "text"
      },
      "source": [
        "# <font color=#003d5c>I. Introducción a Spark</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvmJ5QFeL_9s",
        "colab_type": "text"
      },
      "source": [
        "## <font color=#003d5c>1.1. ¿Por qué Apache Spark?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbpa8W1FNenb",
        "colab_type": "text"
      },
      "source": [
        "[Apache Spark](http://spark.apache.org/) es el motor de procesamiento de datos de [código abierto más activo](https://github.com/apache/spark/graphs/contributors) construido para una mayor velocidad, facilidad de uso y análisis avanzado, con más de 1000 colaboradores en más de 250 organizaciones y con una creciente comunidad de desarrolladores, adoptantes y usuarios. \n",
        "\n",
        "Además, como un motor de cálculo rápido de uso general diseñado para el procesamiento de datos distribuidos a gran escala, Spark soporta múltiples cargas de trabajo a través de un motor unificado compuesto por componentes de Spark que son accesibles por medio de APIs en los lenguajes de programación populares (Scala, Java, Python y R).\n",
        "\n",
        "Por último, Apache Spark se puede implementar en diferentes\n",
        "entornos, así como leer datos de varias fuentes de datos e interactuar con\n",
        "innumerables aplicaciones.\n",
        "\n",
        "<img src=\"https://github.com/mikolarico/spark-course-images/blob/master/spark-architecture-databricks.gif?raw=true\" width=\"600\">\n",
        "\n",
        "En conjunto, este [motor de cómputo unificado](https://cacm.acm.org/magazines/2016/11/209116-apache-spark/abstract) hace de Spark un entorno ideal para diversas cargas de trabajo: ETLs tradicionales, consultas interactivas o ad-hoc (Spark SQL), análisis avanzado (Machine Learning), procesamiento de grafos (GraphX / GraphFrames) y streaming (Streaming estructurado), ya que todos se ejecutan dentro del mismo motor.\n",
        "\n",
        "<img src=\"https://github.com/mikolarico/spark-course-images/blob/master/apache-spark-core-engine.png?raw=true\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X72IX03EMRjh",
        "colab_type": "text"
      },
      "source": [
        "## <font color=#003d5c>1.2. Conceptos, palabras y términos claves de Apache Spark</font>\n",
        "\n",
        "Referencias: \n",
        "\n",
        "\n",
        "1.   [Apache Spark Key Terms Explained - KDnuggets](https://www.kdnuggets.com/2016/06/spark-key-terms-explained.html)\n",
        "2.   [Cluster Configuration Video - Udacity](https://www.youtube.com/watch?v=DpPD5hhvspg&feature=youtu.be)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NeOUl7hrwW_",
        "colab_type": "text"
      },
      "source": [
        "Arquitectura de Spark\n",
        "\n",
        "*   Spark Cluster\n",
        "\n",
        "Colección de máquinas o nodos en la nube o en un centro de datos privado on-premise en el que se encuentra instalado Spark. Entre esas máquinas se encuentran los Spark workers, un Spark Master (también un administrador de clúster en el modo Standalone) y al menos un Spark Driver.\n",
        "\n",
        "*   Spark Master\n",
        "\n",
        "En el modo de despliegue Standalone, el Spark Master actúa como un administrador de recursos y decide cuántos Executors se ejecutarán y en qué Workers del clúster lo harán.\n",
        "\n",
        "*   Spark Worker\n",
        "\n",
        "Al recibir instrucciones del Spark Master, el JVM de Spark Worker lanza los Executors en nombre del Spark Driver. Las aplicaciones de Spark, descompuestas en unidades de tareas, se ejecutan en el Executor de cada Worker.\n",
        "\n",
        "*   Spark Executor\n",
        "\n",
        "Un Spark Executor es un contenedor de JVM con una cantidad asignada de núcleos y memoria con la que Spark ejecuta sus tareas. Es decir, cada nodo Worker lanza su propio Spark Executor, con un número configurable de núcleos (o subprocesos). Además de ejecutar las tareas de Spark, un Executor también almacena todas las particiones de los datos en disco y en memoria caché.\n",
        "\n",
        "*   Spark Driver\n",
        "\n",
        "El programa Driver distribuye las tareas de Spark a cada Executor de cada Worker. El Driver también recibe resultados calculados de las tareas de cada Executor.\n",
        "\n",
        "<img src=\"https://github.com/mikolarico/spark-course-images/blob/master/spark-physical-cluster.png?raw=true\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLGZI52jrah6",
        "colab_type": "text"
      },
      "source": [
        "*   Modos de Despliegue de Spark\n",
        "\n",
        "Spark soporta cuatro modos de despliegue, cada uno con sus propias características con respecto a dónde se ejecutan los componentes de Spark dentro de un clúster. De todos los modos, el modo local, que se ejecuta en un solo nodo, es el más simple y es el que usaremos en esta sesión de Introducción debido a que es muy útil cuando se quiere aprender la sintaxis y cuando se quiere prototipar una solución.\n",
        "\n",
        "<img src=\"https://github.com/mikolarico/spark-course-images/blob/master/spark-mode-deployments.png?raw=true\" width=\"600\">\n",
        "\n",
        "*   SparkSession y SparkContext\n",
        "*   Spark Apps, Jobs, Stages y Tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhr0_L_nruWF",
        "colab_type": "code",
        "outputId": "ceb3ff2b-2945-4a1d-8bf3-008bbb44589a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"hola\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hola\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr52aUvFDJvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaWtTRMVDNGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "db204da3-4ac5-415e-9ef6-f1d4dc519bb4"
      },
      "source": [
        "!ls -l /usr/lib/jvm/java-8-openjdk-amd64"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "lrwxrwxrwx 1 root root   22 Oct 16 20:38 ASSEMBLY_EXCEPTION -> jre/ASSEMBLY_EXCEPTION\n",
            "drwxr-xr-x 2 root root 4096 Dec 18 16:47 bin\n",
            "lrwxrwxrwx 1 root root   41 Oct 16 20:38 docs -> ../../../share/doc/openjdk-8-jre-headless\n",
            "drwxr-xr-x 3 root root 4096 Dec 18 16:47 include\n",
            "drwxr-xr-x 5 root root 4096 Dec 18 16:45 jre\n",
            "drwxr-xr-x 3 root root 4096 Dec 18 16:47 lib\n",
            "drwxr-xr-x 4 root root 4096 Dec 18 16:45 man\n",
            "lrwxrwxrwx 1 root root   20 Oct 16 20:38 src.zip -> ../openjdk-8/src.zip\n",
            "lrwxrwxrwx 1 root root   22 Oct 16 20:38 THIRD_PARTY_README -> jre/THIRD_PARTY_README\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzfRz5NrDRE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6X8vf_FDRAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc7gOsDkEnI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4085d307-6a92-44e1-de51-facb5abe7919"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 60kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=d5781ebc91436f91c19857daa4c2edc258bf828c4e1b93ee5c04edd0cc009915\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMpl005LEqDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi0w7rUEEtYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sVtP0X5MjTK",
        "colab_type": "text"
      },
      "source": [
        "## <font color=#003d5c>1.3. DataFrames, Datasets y Spark SQL</font>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TFydtUQFFa0",
        "colab_type": "text"
      },
      "source": [
        "#### <font color=#003d5c>**Caso de Uso**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsAfJnI4DWa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3c603b25-a194-41c1-af2b-623787807ada"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdfPFUCPDWSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e6e490b-8be9-441d-c039-24e34086129f"
      },
      "source": [
        "%cd /gdrive/'My Drive'/Competiciones/'[03] Datathon Interbank'/'[00] Data'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Competiciones/[03] Datathon Interbank/[00] Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M_CXJynD6QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj6MOn3wD6Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(\"ib_base_inicial_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBTSlMSxE3CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sdf_train = spark.createDataFrame(df_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKbQVspSE2-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "8d4465b2-73a4-418f-c338-3dc8b9a407e6"
      },
      "source": [
        "sdf_train.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----------+---------+--------+------+------------+--------------+\n",
            "|codmes|id_persona|codtarget|  margen|   cem|ingreso_neto|linea_ofrecida|\n",
            "+------+----------+---------+--------+------+------------+--------------+\n",
            "|201901|    165747|        0|    -5.0|   1.0|      1781.0|          1700|\n",
            "|201903|    100117|        0|    -5.0| 478.0|      2106.0|          2100|\n",
            "|201901|     65751|        1|  342.99| 687.0|      3083.0|          4600|\n",
            "|201901|     58047|        0|    -5.0| 182.0|      1814.0|          3600|\n",
            "|201901|    113221|        0|    -5.0| 582.0|      2153.0|          4300|\n",
            "|201903|    247481|        0|    -5.0| 344.0|      1325.0|          1300|\n",
            "|201902|      2651|        0|    -5.0|4507.0|      9344.0|         23300|\n",
            "|201902|      5164|        0|    -5.0| 310.0|      3166.0|          6300|\n",
            "|201902|     81364|        0|    -5.0| 791.0|      1870.0|          1800|\n",
            "|201901|    142634|        0|    -5.0|4058.0|      7342.0|         33000|\n",
            "|201904|     31864|        0|    -5.0| 577.0|      1750.0|          1200|\n",
            "|201903|    204321|        0|    -5.0| 352.0|      1423.0|          3500|\n",
            "|201902|    206604|        1|    -5.0| 531.0|      2520.0|          8800|\n",
            "|201903|    230894|        0|    -5.0|1024.0|      3024.0|         16600|\n",
            "|201903|      2451|        1|   -4.67| 324.0|      4536.0|          6800|\n",
            "|201904|     95347|        1|37.07786| 831.0|      2662.0|          5300|\n",
            "|201901|     13204|        0|    -5.0| 126.0|      4776.0|         11900|\n",
            "|201902|    236904|        0|    -5.0| 409.0|      1955.0|          3900|\n",
            "|201902|     76777|        0|    -5.0|2520.0|      4870.0|         21900|\n",
            "|201903|    230317|        0|    -5.0|1272.0|      3007.0|         12000|\n",
            "+------+----------+---------+--------+------+------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUzaPe1jE271",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6d01ec0-da90-4f95-91bf-0a26f9e671ff"
      },
      "source": [
        "sdf_train.count()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "212665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUHErtrE24p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8bf79672-5117-4997-8094-c851d6b6aeaa"
      },
      "source": [
        "sdf_train.groupby(\"codmes\").agg(\n",
        "                                F.countDistinct(\"id_persona\").alias(\"count_distinct_id_persona\"),\n",
        "                                F.round(F.mean(\"ingreso_neto\"), 4).alias(\"mean_ingreso_neto\"),\n",
        "                                F.round(F.mean(\"linea_ofrecida\"), 4).alias(\"mean_linea_ofrecida\"),\n",
        "                                F.round(F.mean(\"cem\"), 4).alias(\"mean_cem_ofrecida\"),\n",
        "                                F.round(F.mean(\"codtarget\"), 4).alias(\"mean_codtarget\"),\n",
        "                                )\\\n",
        "                           .orderBy(F.desc(\"codmes\"))\\\n",
        "                           .show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------------------+-----------------+-------------------+-----------------+--------------+\n",
            "|codmes|count_distinct_id_persona|mean_ingreso_neto|mean_linea_ofrecida|mean_cem_ofrecida|mean_codtarget|\n",
            "+------+-------------------------+-----------------+-------------------+-----------------+--------------+\n",
            "|201904|                    60065|        3155.0792|          8251.2578|         873.9625|        0.1466|\n",
            "|201903|                    52387|        3045.8381|          7803.4092|         878.5347|        0.1622|\n",
            "|201902|                    46125|        3056.4067|           7608.555|         849.3362|        0.1491|\n",
            "|201901|                    54088|        3270.0494|          8641.0535|         865.0523|        0.1257|\n",
            "+------+-------------------------+-----------------+-------------------+-----------------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMOvdElAD6Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1pM0uB5MSaN",
        "colab_type": "text"
      },
      "source": [
        "## <font color=#003d5c>1.4. Apache Spark for Machine Learning</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl7K1SGJMSUH",
        "colab_type": "text"
      },
      "source": [
        "## <font color=#003d5c>1.5. Spark Streaming y Structured Streaming</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9btkTdP3MSQ2",
        "colab_type": "text"
      },
      "source": [
        "## <font color=#003d5c>1.6. Procesamiento de grafos con GraphFrames</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V29g50FYXDqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}